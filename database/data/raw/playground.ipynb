{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE ALL TEMP .H5 FILES INTO A SINGLE FINAL FILE\n",
    "\n",
    "\n",
    "import csv, ast, os\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 6: Patch to merge all .h5 files ===\n",
    "def merge_all_hdf5_files(final_file=\"final_tick_data.h5\"):\n",
    "    temp_files = [f for f in os.listdir(\".\") if f.endswith(\".h5\") and f != final_file]\n",
    "    with pd.HDFStore(final_file, mode='a') as final_store:\n",
    "        for temp in temp_files:\n",
    "            try:\n",
    "                with pd.HDFStore(temp, mode='r') as temp_store:\n",
    "                    keys = temp_store.keys()\n",
    "                    if not keys:\n",
    "                        print(f\"âš ï¸ Skipping empty file: {temp}\")\n",
    "                        continue\n",
    "                    for key in keys:\n",
    "                        df = temp_store[key]\n",
    "                        final_store.put(key, df, format='table', data_columns=True)\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error reading {temp}: {e}\")\n",
    "            finally:\n",
    "                try:\n",
    "                    os.remove(temp)\n",
    "                    print(f\"ğŸ—‘ï¸ Deleted temp file: {temp}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Could not delete {temp}: {e}\")\n",
    "\n",
    "merge_all_hdf5_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6799d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All tasks complete. Data split by instrument.\n"
     ]
    }
   ],
   "source": [
    "# DECOMPOSE FINAL FILE BY INSTRUMENT\n",
    "\n",
    "\n",
    "import csv, ast, os\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "\n",
    "def decompose_by_instrument(final_file, output_dir=\"split_by_instrument\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with pd.HDFStore(final_file, mode='r') as store:\n",
    "        keys = store.keys()\n",
    "        instrument_groups = defaultdict(list)\n",
    "        for key in keys:\n",
    "            instrument = key.strip(\"/\").split(\"/\")[0]\n",
    "            instrument_groups[instrument].append(key)\n",
    "\n",
    "        for instrument, group_keys in instrument_groups.items():\n",
    "            out_path = os.path.join(output_dir, f\"{instrument}_tick_data.h5\")\n",
    "            with pd.HDFStore(out_path, mode='w') as out_store:\n",
    "                for key in group_keys:\n",
    "                    df = store[key]\n",
    "                    out_store.put(key, df, format='table', data_columns=True)\n",
    "\n",
    "decompose_by_instrument(\"final_tick_data.h5\")\n",
    "print(\"âœ… All tasks complete. Data split by instrument.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6889c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Skipping duplicate key: /ausidxaud/y2023/m07/d30 in ausidxaud\n",
      "ğŸ” Skipping duplicate key: /ausidxaud/y2023/m03/d05 in ausidxaud\n",
      "ğŸ” Skipping duplicate key: /eurusd/y2023/m09/d03 in eurusd\n",
      "ğŸ” Skipping duplicate key: /eurusd/y2023/m03/d05 in eurusd\n",
      "âœ… Merged fetched â†’ raw: eurusd\n",
      "ğŸ” Skipping duplicate key: /usa500idxusd/y2024/m01/d01 in usa500idxusd\n",
      "ğŸ” Skipping duplicate key: /usdcnh/y2024/m05/d19 in usdcnh\n",
      "ğŸ” Skipping duplicate key: /usdcnh/y2022/m06/d05 in usdcnh\n",
      "ğŸ” Skipping duplicate key: /usdcnh/y2019/m05/d26 in usdcnh\n",
      "âœ… Merged fetched â†’ raw: usdcnh\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2025/m07/d20 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdmxn/y2023/m11/d19 in usdmxn\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2025/m04/d06 in usdsek\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2025/m02/d09 in usdsek\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2025/m02/d16 in usdsek\n",
      "ğŸ” Skipping duplicate key: /gbpusd/y2025/m02/d23 in gbpusd\n",
      "ğŸ” Skipping duplicate key: /gbpusd/y2024/m02/d18 in gbpusd\n",
      "ğŸ” Skipping duplicate key: /gbpusd/y2023/m11/d19 in gbpusd\n",
      "ğŸ” Skipping duplicate key: /gbpusd/y2022/m12/d18 in gbpusd\n",
      "ğŸ” Skipping duplicate key: /audusd/y2024/m02/d11 in audusd\n",
      "ğŸ” Skipping duplicate key: /audusd/y2023/m02/d05 in audusd\n",
      "ğŸ” Skipping duplicate key: /audusd/y2021/m02/d14 in audusd\n",
      "ğŸ” Skipping duplicate key: /audusd/y2021/m01/d24 in audusd\n",
      "âœ… Merged fetched â†’ raw: ausidxaud\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2025/m01/d19 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2024/m11/d10 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2025/m01/d01 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2024/m05/d19 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2024/m02/d25 in xauusd\n",
      "ğŸ” Skipping duplicate key: /usdzar/y2024/m03/d03 in usdzar\n",
      "ğŸ” Skipping duplicate key: /usdzar/y2024/m03/d17 in usdzar\n",
      "ğŸ” Skipping duplicate key: /usdzar/y2023/m04/d16 in usdzar\n",
      "ğŸ” Skipping duplicate key: /usdzar/y2021/m02/d28 in usdzar\n",
      "âœ… Merged fetched â†’ raw: usdzar\n",
      "ğŸ” Skipping duplicate key: /usa500idxusd/y2022/m04/d03 in usa500idxusd\n",
      "âœ… Merged fetched â†’ raw: usa500idxusd\n",
      "ğŸ” Skipping duplicate key: /nzdusd/y2023/m01/d15 in nzdusd\n",
      "ğŸ” Skipping duplicate key: /nzdusd/y2022/m12/d11 in nzdusd\n",
      "âœ… Merged fetched â†’ raw: nzdusd\n",
      "ğŸ” Skipping duplicate key: /jpnidxjpy/y2024/m11/d03 in jpnidxjpy\n",
      "ğŸ” Skipping duplicate key: /jpnidxjpy/y2023/m12/d17 in jpnidxjpy\n",
      "âœ… Merged fetched â†’ raw: jpnidxjpy\n",
      "âœ… Merged fetched â†’ raw: usdsgd\n",
      "âœ… Merged fetched â†’ raw: gbpusd\n",
      "ğŸ” Skipping duplicate key: /usdmxn/y2022/m10/d30 in usdmxn\n",
      "ğŸ” Skipping duplicate key: /usdmxn/y2022/m04/d03 in usdmxn\n",
      "ğŸ” Skipping duplicate key: /usdmxn/y2022/m04/d10 in usdmxn\n",
      "ğŸ” Skipping duplicate key: /deuidxeur/y2023/m03/d26 in deuidxeur\n",
      "ğŸ” Skipping duplicate key: /deuidxeur/y2022/m10/d23 in deuidxeur\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2023/m04/d23 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2023/m01/d08 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2022/m12/d18 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2022/m05/d08 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2022/m03/d13 in xauusd\n",
      "ğŸ” Skipping duplicate key: /xauusd/y2020/m05/d03 in xauusd\n",
      "âœ… Merged fetched â†’ raw: xauusd\n",
      "âœ… Merged fetched â†’ raw: audusd\n",
      "ğŸ” Skipping duplicate key: /lightcmdusd/y2022/m04/d17 in lightcmdusd\n",
      "ğŸ” Skipping duplicate key: /usdcad/y2023/m11/d05 in usdcad\n",
      "ğŸ” Skipping duplicate key: /usdcad/y2023/m10/d22 in usdcad\n",
      "ğŸ” Skipping duplicate key: /usdcad/y2023/m02/d19 in usdcad\n",
      "ğŸ” Skipping duplicate key: /usdcad/y2022/m12/d11 in usdcad\n",
      "âœ… Merged fetched â†’ raw: usdcad\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2024/m12/d08 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2024/m09/d01 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2023/m01/d08 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2022/m12/d04 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdjpy/y2023/m02/d12 in usdjpy\n",
      "ğŸ” Skipping duplicate key: /usdjpy/y2021/m05/d30 in usdjpy\n",
      "âœ… Merged fetched â†’ raw: usdjpy\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m11/d26 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m07/d09 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m04/d09 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m02/d12 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m02/d26 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2023/m01/d29 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2020/m07/d12 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2018/m12/d16 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2018/m12/d23 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2017/m11/d12 in xagusd\n",
      "ğŸ” Skipping duplicate key: /xagusd/y2017/m09/d10 in xagusd\n",
      "âœ… Merged fetched â†’ raw: xagusd\n",
      "ğŸ” Skipping duplicate key: /usa30idxusd/y2023/m12/d17 in usa30idxusd\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2020/m11/d29 in usdchf\n",
      "ğŸ” Skipping duplicate key: /usdchf/y2020/m02/d16 in usdchf\n",
      "âœ… Merged fetched â†’ raw: usdchf\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2024/m08/d18 in usdsek\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2024/m01/d07 in usdsek\n",
      "âœ… Merged fetched â†’ raw: usdmxn\n",
      "ğŸ” Skipping duplicate key: /usatechidxusd/y2023/m02/d26 in usatechidxusd\n",
      "âœ… Merged fetched â†’ raw: usatechidxusd\n",
      "ğŸ” Skipping duplicate key: /gbridxgbp/y2023/m06/d04 in gbridxgbp\n",
      "ğŸ” Skipping duplicate key: /gbridxgbp/y2022/m12/d04 in gbridxgbp\n",
      "âœ… Merged fetched â†’ raw: gbridxgbp\n",
      "âœ… Merged fetched â†’ raw: deuidxeur\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2023/m01/d29 in usdsek\n",
      "ğŸ” Skipping duplicate key: /usdsek/y2021/m02/d14 in usdsek\n",
      "âœ… Merged fetched â†’ raw: usdsek\n",
      "ğŸ” Skipping duplicate key: /usa30idxusd/y2023/m01/d08 in usa30idxusd\n",
      "ğŸ” Skipping duplicate key: /usa30idxusd/y2022/m08/d21 in usa30idxusd\n",
      "âœ… Merged fetched â†’ raw: usa30idxusd\n",
      "âœ… Merged fetched â†’ raw: lightcmdusd\n"
     ]
    }
   ],
   "source": [
    "# MERGE TO RAW FILES\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def merge_instrument_file(instrument, fetched_dir=\"split_by_instrument\", raw_dir=\"./2015_tick_data\"):\n",
    "    fetched_path = os.path.join(fetched_dir, f\"{instrument}_tick_data.h5\")\n",
    "    raw_path = os.path.join(raw_dir, f\"{instrument}_tick_data.h5\")\n",
    "\n",
    "    if not os.path.exists(fetched_path):\n",
    "        print(f\"âš ï¸ Fetched file missing: {instrument}\")\n",
    "        return\n",
    "    if not os.path.exists(raw_path):\n",
    "        print(f\"âš ï¸ Raw file missing: {instrument}\")\n",
    "        return\n",
    "\n",
    "    with pd.HDFStore(raw_path, mode='a') as raw_store, pd.HDFStore(fetched_path, mode='r') as fetched_store:\n",
    "        for key in fetched_store.keys():\n",
    "            if key in raw_store:\n",
    "                print(f\"ğŸ” Skipping duplicate key: {key} in {instrument}\")\n",
    "                continue\n",
    "            df = fetched_store[key]\n",
    "            raw_store.put(key, df, format='table', data_columns=True)\n",
    "\n",
    "    print(f\"âœ… Merged fetched â†’ raw: {instrument}\")\n",
    "\n",
    "def main():\n",
    "    fetched_dir = \"split_by_instrument\"     # Correct folder for fetched files\n",
    "    raw_dir = \"./2015_tick_data\"            # Correct folder for raw files\n",
    "\n",
    "    # Get list of instruments based on fetched files\n",
    "    instruments = [\n",
    "        filename.replace(\"_tick_data.h5\", \"\")\n",
    "        for filename in os.listdir(fetched_dir)\n",
    "        if filename.endswith(\"_tick_data.h5\")\n",
    "    ]\n",
    "\n",
    "    # Run merge in parallel\n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        for instrument in instruments:\n",
    "            executor.submit(merge_instrument_file, instrument, fetched_dir, raw_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
